{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. 토픽 모델링",
      "provenance": [],
      "authorship_tag": "ABX9TyMxaKt6aRdKRxqZ/aGuGG22",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungEun-IN/ML/blob/main/%EB%94%A5%20%EB%9F%AC%EB%8B%9D%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/4_%ED%86%A0%ED%94%BD_%EB%AA%A8%EB%8D%B8%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7WEWI-atE_d"
      },
      "source": [
        "#잠재 의미 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHy28IoGsWH9",
        "outputId": "2627cf68-0233-4fd1-b99c-aa8c6a9feb5a"
      },
      "source": [
        "import numpy as np\n",
        "A=np.array([[0,0,0,1,0,1,1,0,0],[0,0,0,1,1,0,1,0,0],[0,1,1,0,2,0,0,0,0],[1,0,0,0,0,0,0,1,1]])\n",
        "np.shape(A)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC9vA_uctckv"
      },
      "source": [
        "Full SVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYw7bDfjsiBE"
      },
      "source": [
        "U, s, VT = np.linalg.svd(A, full_matrices = True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXTCqhoQsm3z",
        "outputId": "f4a8bcd8-5edb-49e9-db5a-b0ebb84c0d6b"
      },
      "source": [
        "print(U.round(2))\n",
        "np.shape(U)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.24  0.75  0.   -0.62]\n",
            " [-0.51  0.44 -0.    0.74]\n",
            " [-0.83 -0.49 -0.   -0.27]\n",
            " [-0.   -0.    1.    0.  ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHpuhPY3ssuE",
        "outputId": "11be8907-c268-4c33-afd1-0769b5325612"
      },
      "source": [
        "print(s.round(2))\n",
        "np.shape(s)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.69 2.05 1.73 0.77]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLQZOdMXsvL7",
        "outputId": "5c3fa840-3285-44b4-a2c3-c1cb00c1401a"
      },
      "source": [
        "S = np.zeros((4, 9)) # 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
        "S[:4, :4] = np.diag(s) # 특이값을 대각행렬에 삽입\n",
        "print(S.round(2))\n",
        "np.shape(S)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0Tyy6GstBtb",
        "outputId": "5a3b7cbe-9afe-4ffb-be65-3e6e155674ad"
      },
      "source": [
        "print(VT.round(2))\n",
        "np.shape(VT)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
            " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
            " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
            " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
            " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
            " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
            " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
            " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
            " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhWH4LGZtV4S",
        "outputId": "ad79248b-cba7-4820-8215-588053fed7b5"
      },
      "source": [
        "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz9CHj9NtfMd"
      },
      "source": [
        "Truncated SVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV8EyhgStjHz",
        "outputId": "e3e064e4-be4a-4f70-eed3-b1695afa3210"
      },
      "source": [
        "S=S[:2,:2]\n",
        "print(S.round(2))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.69 0.  ]\n",
            " [0.   2.05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzhAccGttmg8",
        "outputId": "66d57351-6d77-414a-f39e-479d9c007f34"
      },
      "source": [
        "U=U[:,:2]\n",
        "print(U.round(2))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.24  0.75]\n",
            " [-0.51  0.44]\n",
            " [-0.83 -0.49]\n",
            " [-0.   -0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyPpG14hto5s",
        "outputId": "8d383b80-993f-4f62-f7cb-dd00fa0b7c71"
      },
      "source": [
        "VT=VT[:2,:]\n",
        "print(VT.round(2))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
            " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxdqpVyOtxu8",
        "outputId": "2f5f14e3-746e-469c-be45-602ef23a9d47"
      },
      "source": [
        "A_prime=np.dot(np.dot(U,S), VT)\n",
        "print(A)\n",
        "print(A_prime.round(2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 1 0 1 1 0 0]\n",
            " [0 0 0 1 1 0 1 0 0]\n",
            " [0 1 1 0 2 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 1 1]]\n",
            "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
            " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
            " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARtllTYit7Yt"
      },
      "source": [
        "##실습을 통한 이해"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpysBlEkuG1q"
      },
      "source": [
        "1) 뉴스그룹 데이터에 대한 이해"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFRyt6Vvt7Dj",
        "outputId": "280520b3-6288-4e23-f5a0-c07c052389d9"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data\n",
        "len(documents)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "umWuw-Z3uQrL",
        "outputId": "eb9b86e1-df07-4a57-f781-05602995b90d"
      },
      "source": [
        "documents[1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBm1EXH6uUBt",
        "outputId": "b69b1e68-904d-4019-ff0b-7313800b11ee"
      },
      "source": [
        "print(dataset.target_names)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo1IeRi6uX7F"
      },
      "source": [
        "2) 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzg9J0qJuaFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6e52fc-2b5c-4c64-95b0-0509a46235c1"
      },
      "source": [
        "news_df = pd.DataFrame({'document':documents})\n",
        "# 특수 문자 제거\n",
        "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
        "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
        "# 전체 단어에 대한 소문자 변환\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6FgsHT926rWw",
        "outputId": "0d9c74db-1781-4168-c4fc-d8cd508e973d"
      },
      "source": [
        "news_df['clean_doc'][1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_1GG7b97eZr",
        "outputId": "5b705c87-06ac-45a9-9f2e-ba84832362ba"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlFr4fn67vV0",
        "outputId": "ba23f28a-d793-4c79-d886-185f439493c7"
      },
      "source": [
        "import nltk \n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keYE0Bit6zTo"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english') # NLTK로부터 불용어를 받아옵니다.\n",
        "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "# 불용어를 제거합니다."
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8ofUQTq7952",
        "outputId": "6de30827-508c-405b-8e60-6d0de26294b1"
      },
      "source": [
        "print(tokenized_doc[1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C55CQvgI8QCu"
      },
      "source": [
        "3) TF-IDF 행렬 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3DQn6748F83"
      },
      "source": [
        "# 역토큰화 (토큰화 작업을 역으로 되돌림)\n",
        "detokenized_doc = []\n",
        "for i in range(len(news_df)):\n",
        "    t = ' '.join(tokenized_doc[i])\n",
        "    detokenized_doc.append(t)\n",
        "\n",
        "news_df['clean_doc'] = detokenized_doc"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ToGWY0Ps8IR3",
        "outputId": "356ddaf4-17d9-431a-8aad-686838f1116f"
      },
      "source": [
        "news_df['clean_doc'][1]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztUUC3br8LLJ",
        "outputId": "f20d7352-ca20-4494-d1a7-4d48ffde629f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', \n",
        "max_features= 1000, # 상위 1,000개의 단어를 보존 \n",
        "max_df = 0.5, \n",
        "smooth_idf=True)\n",
        "\n",
        "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
        "X.shape # TF-IDF 행렬의 크기 확인"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moAnAnXJ8TUe"
      },
      "source": [
        "4) 토픽 모델링(Topic Modeling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX8uIp0X8V0c",
        "outputId": "1a272b10-ec4d-49cf-a07b-0e592cb5ee70"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
        "svd_model.fit(X)\n",
        "len(svd_model.components_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQiKLc4b8Y-v",
        "outputId": "50242ff6-401c-40fb-875e-507405660e12"
      },
      "source": [
        "np.shape(svd_model.components_)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpvvQl8N8bb-",
        "outputId": "c5ce1f1c-859e-4bc9-c1ee-bf5a67985eab"
      },
      "source": [
        "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
        "\n",
        "def get_topics(components, feature_names, n=5):\n",
        "    for idx, topic in enumerate(components):\n",
        "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
        "get_topics(svd_model.components_,terms)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: [('like', 0.21386), ('know', 0.20046), ('people', 0.19293), ('think', 0.17805), ('good', 0.15128)]\n",
            "Topic 2: [('thanks', 0.32888), ('windows', 0.29088), ('card', 0.18069), ('drive', 0.17455), ('mail', 0.15111)]\n",
            "Topic 3: [('game', 0.37064), ('team', 0.32443), ('year', 0.28154), ('games', 0.2537), ('season', 0.18419)]\n",
            "Topic 4: [('drive', 0.53324), ('scsi', 0.20165), ('hard', 0.15628), ('disk', 0.15578), ('card', 0.13994)]\n",
            "Topic 5: [('windows', 0.40399), ('file', 0.25436), ('window', 0.18044), ('files', 0.16078), ('program', 0.13894)]\n",
            "Topic 6: [('chip', 0.16114), ('government', 0.16009), ('mail', 0.15625), ('space', 0.1507), ('information', 0.13562)]\n",
            "Topic 7: [('like', 0.67086), ('bike', 0.14236), ('chip', 0.11169), ('know', 0.11139), ('sounds', 0.10371)]\n",
            "Topic 8: [('card', 0.46633), ('video', 0.22137), ('sale', 0.21266), ('monitor', 0.15463), ('offer', 0.14643)]\n",
            "Topic 9: [('know', 0.46047), ('card', 0.33605), ('chip', 0.17558), ('government', 0.1522), ('video', 0.14356)]\n",
            "Topic 10: [('good', 0.42756), ('know', 0.23039), ('time', 0.1882), ('bike', 0.11406), ('jesus', 0.09027)]\n",
            "Topic 11: [('think', 0.78469), ('chip', 0.10899), ('good', 0.10635), ('thanks', 0.09123), ('clipper', 0.07946)]\n",
            "Topic 12: [('thanks', 0.36824), ('good', 0.22729), ('right', 0.21559), ('bike', 0.21037), ('problem', 0.20894)]\n",
            "Topic 13: [('good', 0.36212), ('people', 0.33985), ('windows', 0.28385), ('know', 0.26232), ('file', 0.18422)]\n",
            "Topic 14: [('space', 0.39946), ('think', 0.23258), ('know', 0.18074), ('nasa', 0.15174), ('problem', 0.12957)]\n",
            "Topic 15: [('space', 0.31613), ('good', 0.3094), ('card', 0.22603), ('people', 0.17476), ('time', 0.14496)]\n",
            "Topic 16: [('people', 0.48156), ('problem', 0.19961), ('window', 0.15281), ('time', 0.14664), ('game', 0.12871)]\n",
            "Topic 17: [('time', 0.34465), ('bike', 0.27303), ('right', 0.25557), ('windows', 0.1997), ('file', 0.19118)]\n",
            "Topic 18: [('time', 0.5973), ('problem', 0.15504), ('file', 0.14956), ('think', 0.12847), ('israel', 0.10903)]\n",
            "Topic 19: [('file', 0.44163), ('need', 0.26633), ('card', 0.18388), ('files', 0.17453), ('right', 0.15448)]\n",
            "Topic 20: [('problem', 0.33006), ('file', 0.27651), ('thanks', 0.23578), ('used', 0.19206), ('space', 0.13185)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpa6oMPq8t8Y"
      },
      "source": [
        "# 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLU0xntx_QUR"
      },
      "source": [
        "1) 정수 인코딩과 단어 집합 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uSrstrb8v6A",
        "outputId": "5325a12c-0e46-4b6c-d54f-69a020a80bc7"
      },
      "source": [
        "tokenized_doc[:5]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [well, sure, story, seem, biased, disagree, st...\n",
              "1    [yeah, expect, people, read, actually, accept,...\n",
              "2    [although, realize, principle, strongest, poin...\n",
              "3    [notwithstanding, legitimate, fuss, proposal, ...\n",
              "4    [well, change, scoring, playoff, pool, unfortu...\n",
              "Name: clean_doc, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGNxok4d_Cmz",
        "outputId": "2008b10f-ba89-4064-911e-a514f1bea34d"
      },
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(tokenized_doc)\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
        "print(corpus[1]) # 수행된 결과에서 두번째 뉴스 출력. 첫번째 문서의 인덱스는 0"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3345zIOo_H0R",
        "outputId": "464677f6-24ae-42f1-91a5-2e2b4acb0e1d"
      },
      "source": [
        "print(dictionary[66])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faith\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acYeXTIS_J92",
        "outputId": "a5487c7d-8dab-4ea4-9f5c-e66656b9324e"
      },
      "source": [
        "len(dictionary)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64281"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjPNEn2a_SvX"
      },
      "source": [
        "2) LDA 모델 훈련시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PO3M1mw_MN6",
        "outputId": "7ad310e7-90a5-489e-a962-ca11e496c05b"
      },
      "source": [
        "import gensim\n",
        "NUM_TOPICS = 20 #20개의 토픽, k=20\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "topics = ldamodel.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.036*\"output\" + 0.027*\"entry\" + 0.017*\"file\" + 0.014*\"program\"')\n",
            "(1, '0.010*\"nrhj\" + 0.007*\"wwiz\" + 0.006*\"bxom\" + 0.006*\"gizw\"')\n",
            "(2, '0.017*\"bike\" + 0.011*\"cover\" + 0.007*\"motorcycle\" + 0.007*\"lock\"')\n",
            "(3, '0.013*\"picture\" + 0.013*\"henrik\" + 0.008*\"guidelines\" + 0.007*\"master\"')\n",
            "(4, '0.012*\"encryption\" + 0.010*\"chip\" + 0.010*\"keys\" + 0.009*\"clipper\"')\n",
            "(5, '0.010*\"tobacco\" + 0.009*\"nasa\" + 0.006*\"smokeless\" + 0.006*\"colorado\"')\n",
            "(6, '0.014*\"water\" + 0.007*\"nuclear\" + 0.007*\"rockefeller\" + 0.006*\"hash\"')\n",
            "(7, '0.013*\"israel\" + 0.008*\"israeli\" + 0.008*\"health\" + 0.007*\"medical\"')\n",
            "(8, '0.016*\"year\" + 0.016*\"game\" + 0.013*\"team\" + 0.013*\"games\"')\n",
            "(9, '0.012*\"know\" + 0.011*\"would\" + 0.010*\"like\" + 0.009*\"people\"')\n",
            "(10, '0.010*\"would\" + 0.009*\"people\" + 0.007*\"think\" + 0.006*\"believe\"')\n",
            "(11, '0.015*\"mouse\" + 0.014*\"keyboard\" + 0.009*\"food\" + 0.006*\"candida\"')\n",
            "(12, '0.014*\"armenian\" + 0.012*\"armenians\" + 0.010*\"jews\" + 0.010*\"turkish\"')\n",
            "(13, '0.012*\"would\" + 0.010*\"people\" + 0.009*\"government\" + 0.005*\"right\"')\n",
            "(14, '0.010*\"period\" + 0.010*\"play\" + 0.009*\"hockey\" + 0.008*\"team\"')\n",
            "(15, '0.010*\"would\" + 0.009*\"like\" + 0.008*\"drive\" + 0.008*\"know\"')\n",
            "(16, '0.009*\"ground\" + 0.008*\"wire\" + 0.008*\"power\" + 0.007*\"condition\"')\n",
            "(17, '0.022*\"space\" + 0.008*\"science\" + 0.006*\"nasa\" + 0.006*\"earth\"')\n",
            "(18, '0.017*\"window\" + 0.011*\"display\" + 0.008*\"widget\" + 0.008*\"image\"')\n",
            "(19, '0.018*\"file\" + 0.010*\"files\" + 0.010*\"available\" + 0.008*\"program\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZg_-stb_hay",
        "outputId": "277a57f5-5b6e-43d8-9795-b489e4250192"
      },
      "source": [
        "print(ldamodel.print_topics())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.036*\"output\" + 0.027*\"entry\" + 0.017*\"file\" + 0.014*\"program\" + 0.012*\"build\" + 0.012*\"printf\" + 0.012*\"char\" + 0.012*\"oname\" + 0.011*\"line\" + 0.011*\"stream\"'), (1, '0.010*\"nrhj\" + 0.007*\"wwiz\" + 0.006*\"bxom\" + 0.006*\"gizw\" + 0.005*\"tbxn\" + 0.005*\"bhjn\" + 0.005*\"bxlt\" + 0.005*\"easter\" + 0.004*\"wmbxn\" + 0.004*\"nriz\"'), (2, '0.017*\"bike\" + 0.011*\"cover\" + 0.007*\"motorcycle\" + 0.007*\"lock\" + 0.006*\"rider\" + 0.006*\"riding\" + 0.006*\"ride\" + 0.005*\"good\" + 0.005*\"copies\" + 0.004*\"annual\"'), (3, '0.013*\"picture\" + 0.013*\"henrik\" + 0.008*\"guidelines\" + 0.007*\"master\" + 0.007*\"slave\" + 0.007*\"sleeve\" + 0.006*\"cross\" + 0.005*\"cview\" + 0.004*\"cooper\" + 0.004*\"temp\"'), (4, '0.012*\"encryption\" + 0.010*\"chip\" + 0.010*\"keys\" + 0.009*\"clipper\" + 0.009*\"information\" + 0.008*\"security\" + 0.008*\"system\" + 0.008*\"privacy\" + 0.007*\"public\" + 0.007*\"technology\"'), (5, '0.010*\"tobacco\" + 0.009*\"nasa\" + 0.006*\"smokeless\" + 0.006*\"colorado\" + 0.005*\"dept\" + 0.005*\"coli\" + 0.004*\"ames\" + 0.004*\"outlets\" + 0.004*\"cycle\" + 0.004*\"radio\"'), (6, '0.014*\"water\" + 0.007*\"nuclear\" + 0.007*\"rockefeller\" + 0.006*\"hash\" + 0.006*\"marriage\" + 0.005*\"exhaust\" + 0.005*\"georgia\" + 0.004*\"patent\" + 0.004*\"married\" + 0.004*\"columbia\"'), (7, '0.013*\"israel\" + 0.008*\"israeli\" + 0.008*\"health\" + 0.007*\"medical\" + 0.005*\"number\" + 0.005*\"arab\" + 0.005*\"among\" + 0.005*\"years\" + 0.004*\"center\" + 0.004*\"research\"'), (8, '0.016*\"year\" + 0.016*\"game\" + 0.013*\"team\" + 0.013*\"games\" + 0.009*\"last\" + 0.009*\"good\" + 0.009*\"players\" + 0.007*\"season\" + 0.006*\"better\" + 0.006*\"would\"'), (9, '0.012*\"know\" + 0.011*\"would\" + 0.010*\"like\" + 0.009*\"people\" + 0.009*\"time\" + 0.009*\"said\" + 0.008*\"think\" + 0.008*\"going\" + 0.007*\"back\" + 0.007*\"could\"'), (10, '0.010*\"would\" + 0.009*\"people\" + 0.007*\"think\" + 0.006*\"believe\" + 0.006*\"jesus\" + 0.005*\"know\" + 0.005*\"like\" + 0.005*\"even\" + 0.005*\"many\" + 0.004*\"true\"'), (11, '0.015*\"mouse\" + 0.014*\"keyboard\" + 0.009*\"food\" + 0.006*\"candida\" + 0.005*\"normal\" + 0.005*\"font\" + 0.005*\"diet\" + 0.005*\"problems\" + 0.004*\"type\" + 0.004*\"fonts\"'), (12, '0.014*\"armenian\" + 0.012*\"armenians\" + 0.010*\"jews\" + 0.010*\"turkish\" + 0.007*\"greek\" + 0.006*\"people\" + 0.006*\"turkey\" + 0.005*\"russian\" + 0.005*\"jewish\" + 0.005*\"killed\"'), (13, '0.012*\"would\" + 0.010*\"people\" + 0.009*\"government\" + 0.005*\"right\" + 0.005*\"state\" + 0.004*\"make\" + 0.004*\"rights\" + 0.004*\"public\" + 0.004*\"states\" + 0.004*\"even\"'), (14, '0.010*\"period\" + 0.010*\"play\" + 0.009*\"hockey\" + 0.008*\"team\" + 0.007*\"game\" + 0.006*\"pittsburgh\" + 0.006*\"chicago\" + 0.006*\"power\" + 0.005*\"detroit\" + 0.005*\"season\"'), (15, '0.010*\"would\" + 0.009*\"like\" + 0.008*\"drive\" + 0.008*\"know\" + 0.007*\"thanks\" + 0.007*\"system\" + 0.007*\"anyone\" + 0.007*\"windows\" + 0.006*\"also\" + 0.006*\"problem\"'), (16, '0.009*\"ground\" + 0.008*\"wire\" + 0.008*\"power\" + 0.007*\"condition\" + 0.007*\"sale\" + 0.006*\"offer\" + 0.006*\"asking\" + 0.006*\"excellent\" + 0.006*\"used\" + 0.005*\"shipping\"'), (17, '0.022*\"space\" + 0.008*\"science\" + 0.006*\"nasa\" + 0.006*\"earth\" + 0.005*\"launch\" + 0.004*\"satellite\" + 0.004*\"research\" + 0.004*\"data\" + 0.004*\"also\" + 0.004*\"scientific\"'), (18, '0.017*\"window\" + 0.011*\"display\" + 0.008*\"widget\" + 0.008*\"image\" + 0.008*\"motif\" + 0.007*\"application\" + 0.007*\"program\" + 0.007*\"color\" + 0.007*\"using\" + 0.007*\"data\"'), (19, '0.018*\"file\" + 0.010*\"files\" + 0.010*\"available\" + 0.008*\"program\" + 0.008*\"information\" + 0.007*\"also\" + 0.007*\"list\" + 0.007*\"send\" + 0.006*\"info\" + 0.006*\"mail\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6q0RSVQagIa"
      },
      "source": [
        "3) 문서 별 토픽 분포 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7YiGv_oahsU",
        "outputId": "9adf6852-9f3a-4665-e9c4-9de688fa1030"
      },
      "source": [
        "for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "    if i==5:\n",
        "        break\n",
        "    print(i,'번째 문서의 topic 비율은',topic_list)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 번째 문서의 topic 비율은 [(7, 0.19174105), (10, 0.39527777), (11, 0.083895825), (12, 0.20549808), (17, 0.11149049)]\n",
            "1 번째 문서의 topic 비율은 [(8, 0.097056575), (10, 0.88099223)]\n",
            "2 번째 문서의 topic 비율은 [(7, 0.30763614), (9, 0.19907638), (10, 0.23895504), (13, 0.13102569), (16, 0.029219655), (19, 0.08279678)]\n",
            "3 번째 문서의 topic 비율은 [(0, 0.02180202), (1, 0.01567164), (4, 0.2584658), (9, 0.13336603), (10, 0.12155769), (12, 0.11223562), (13, 0.21823429), (15, 0.10971171)]\n",
            "4 번째 문서의 topic 비율은 [(0, 0.03278948), (10, 0.5848198), (14, 0.3509092)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts5I1GUEanB6"
      },
      "source": [
        "def make_topictable_per_doc(ldamodel, corpus):\n",
        "    topic_table = pd.DataFrame()\n",
        "\n",
        "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
        "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n",
        "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
        "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
        "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%), \n",
        "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
        "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
        "\n",
        "        # 모든 문서에 대해서 각각 아래를 수행\n",
        "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
        "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
        "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
        "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
        "            else:\n",
        "                break\n",
        "    return(topic_table)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Xu8pA6auoL"
      },
      "source": [
        "topictable = make_topictable_per_doc(ldamodel, corpus)\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Utbo0pW1gg6r",
        "outputId": "190d69dd-a709-48fe-ded7-94c8ad6bf25e"
      },
      "source": [
        "topictable.columns = ['가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
        "topictable[:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>가장 비중이 높은 토픽</th>\n",
              "      <th>가장 높은 토픽의 비중</th>\n",
              "      <th>각 토픽의 비중</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>[(7, 0.19174226), (10, 0.395275), (11, 0.08389...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>[(8, 0.0969632), (10, 0.8810856)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.3076</td>\n",
              "      <td>[(7, 0.30764067), (9, 0.19910125), (10, 0.2389...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2585</td>\n",
              "      <td>[(0, 0.0218024), (1, 0.01567164), (4, 0.258462...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.5851</td>\n",
              "      <td>[(0, 0.032468144), (10, 0.58513737), (14, 0.35...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.5601</td>\n",
              "      <td>[(4, 0.25863403), (9, 0.09372278), (10, 0.5600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>19.0</td>\n",
              "      <td>0.7577</td>\n",
              "      <td>[(9, 0.014516796), (10, 0.028578185), (15, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.5021</td>\n",
              "      <td>[(5, 0.016666666), (7, 0.11102964), (9, 0.5020...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>19.0</td>\n",
              "      <td>0.4483</td>\n",
              "      <td>[(3, 0.04479425), (9, 0.28387448), (10, 0.2013...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15.0</td>\n",
              "      <td>0.4701</td>\n",
              "      <td>[(4, 0.053710047), (9, 0.2239782), (10, 0.1699...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   가장 비중이 높은 토픽  ...                                           각 토픽의 비중\n",
              "0          10.0  ...  [(7, 0.19174226), (10, 0.395275), (11, 0.08389...\n",
              "1          10.0  ...                  [(8, 0.0969632), (10, 0.8810856)]\n",
              "2           7.0  ...  [(7, 0.30764067), (9, 0.19910125), (10, 0.2389...\n",
              "3           4.0  ...  [(0, 0.0218024), (1, 0.01567164), (4, 0.258462...\n",
              "4          10.0  ...  [(0, 0.032468144), (10, 0.58513737), (14, 0.35...\n",
              "5          10.0  ...  [(4, 0.25863403), (9, 0.09372278), (10, 0.5600...\n",
              "6          19.0  ...  [(9, 0.014516796), (10, 0.028578185), (15, 0.1...\n",
              "7           9.0  ...  [(5, 0.016666666), (7, 0.11102964), (9, 0.5020...\n",
              "8          19.0  ...  [(3, 0.04479425), (9, 0.28387448), (10, 0.2013...\n",
              "9          15.0  ...  [(4, 0.053710047), (9, 0.2239782), (10, 0.1699...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}