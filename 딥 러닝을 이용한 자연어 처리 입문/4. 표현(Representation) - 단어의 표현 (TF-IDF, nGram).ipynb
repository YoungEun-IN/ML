{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_TVhSXBJk2g"
   },
   "source": [
    "# 단어의 표현 (Word Representation)\n",
    "\n",
    "\n",
    "기계는 문자를 그대로 인식할 수 없기때문에 숫자로 변환\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwB1D_6MP8bg"
   },
   "source": [
    "#1 TF-IDF를 활용한 단어 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HGBaQ4bXuSo"
   },
   "source": [
    "##1-1 직접 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8lmTqCA9ZBs"
   },
   "source": [
    "weighting schema|weight|설명\n",
    "--|--|--\n",
    "term frequency|<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/91699003abf4fe8bdf861bbce08e73e71acf5fd4\"/>|=토큰빈도/문서내토큰빈도\n",
    "inverse document frequency|<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/864fcfdc0c16344c11509f724f1aa7081cf9f657\" />|=log(총문서갯수/(토큰이 등장한 문서수))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y56mwVir0L3a"
   },
   "outputs": [],
   "source": [
    "d1 = \"The cat sat on my face I hate a cat\"\n",
    "d2 = \"The dog sat on my bed I love a dog\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def tf(t, d) :\n",
    "  return d.count(t) / len(d)\n",
    "\n",
    "def idf (t, D) :\n",
    "  N = len(D)\n",
    "  n = len([True for d in D if t in d])\n",
    "  return np.log(N/n)\n",
    "\n",
    "def tfidf (t,d,D) :\n",
    "  return tf(t,d) * idf(t,D)\n",
    "\n",
    "def tokenizer(d) :\n",
    "  return d.split()\n",
    "\n",
    "def tdidf_score(D):\n",
    "    docs = [tokenizer(d) for d in D]\n",
    "    result = []\n",
    "    for d in docs:\n",
    "        result.append([(t, tfidf(t, d, docs)) for t in d])\n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 0.0),\n",
       "  ('cat', 0.13862943611198905),\n",
       "  ('sat', 0.0),\n",
       "  ('on', 0.0),\n",
       "  ('my', 0.0),\n",
       "  ('face', 0.06931471805599453),\n",
       "  ('I', 0.0),\n",
       "  ('hate', 0.06931471805599453),\n",
       "  ('a', 0.0),\n",
       "  ('cat', 0.13862943611198905)],\n",
       " [('The', 0.0),\n",
       "  ('dog', 0.13862943611198905),\n",
       "  ('sat', 0.0),\n",
       "  ('on', 0.0),\n",
       "  ('my', 0.0),\n",
       "  ('bed', 0.06931471805599453),\n",
       "  ('I', 0.0),\n",
       "  ('love', 0.06931471805599453),\n",
       "  ('a', 0.0),\n",
       "  ('dog', 0.13862943611198905)]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdidf_score([d1,d2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fjur4eRRK_x"
   },
   "source": [
    "## 1-2 sklearn 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "docs = [d1, d2]\n",
    "count_vect = CountVectorizer()\n",
    "countv = count_vect.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mp-oidh9QAEY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 0 1 1 0 1 1 1 1]\n",
      " [1 0 2 0 0 1 1 1 1 1]]\n",
      "{'the': 9, 'cat': 1, 'sat': 8, 'on': 7, 'my': 6, 'face': 3, 'hate': 4, 'dog': 2, 'bed': 0, 'love': 5}\n"
     ]
    }
   ],
   "source": [
    "print(countv.toarray())\n",
    "print(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6LAITxYuQDL8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.70600557 0.         0.35300279 0.35300279 0.\n",
      "  0.25116439 0.25116439 0.25116439 0.25116439]\n",
      " [0.35300279 0.         0.70600557 0.         0.         0.35300279\n",
      "  0.25116439 0.25116439 0.25116439 0.25116439]]\n",
      "{'the': 9, 'cat': 1, 'sat': 8, 'on': 7, 'my': 6, 'face': 3, 'hate': 4, 'dog': 2, 'bed': 0, 'love': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidfv = tfidf_vect.fit_transform(docs)\n",
    "print(tfidfv.toarray())\n",
    "print(tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOH8TC8DROUZ"
   },
   "source": [
    "## 1-3 gensim 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9YvqERDRRUMM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.8164965809277261), (4, 0.4082482904638631), (5, 0.4082482904638631)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim import corpora\n",
    "\n",
    "doc_ls = [d.split() for d in docs]\n",
    "id2word = corpora.Dictionary(doc_ls)\n",
    "bow = [id2word.doc2bow(d) for d in doc_ls]\n",
    "\n",
    "tfidf = TfidfModel(bow)\n",
    "tfidf[bow[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GhHpb-SDINae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7fR-R8oRTly"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "08 실습 - 표현(Representation) - 단어의 표현 (TF-IDF, nGram)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
