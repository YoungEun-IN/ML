## Volumes

포드를 생성하고 로컬 호스트 `/data` 디렉토리에 매핑된 볼륨을 마운트하고 싶다고 가정해 보겠습니다. 이 디렉토리는 런타임 중에 생성된 파일을 저장합니다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: random-number-generator
  labels:
    name: random-number-generator
spec:
  containers:
  - name: alpine
    image: alpine
    command:
      - "/bin/sh"
      - "-c"
    args: 
      - "shuf -i 0-100 -n 1 >> /opt/number.out;"
    resources:
      limits:
        memory: "128Mi"
        cpu: "500m"
    ports:
      - containerPort: 8383
    volumes:
    - name: data-volume
      hostPath:
        path: /data
        type: Directory
```

그러나 다중 노드 클러스터가 있고 AWS EBS 등과 같은 일부 스토리지 솔루션이 있는 경우에는 어떻게 될까요? 그러면 localhost 경로를 사용할 수 없습니다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: random-number-generator
  labels:
    name: random-number-generator
spec:
  containers:
  - name: alpine
    image: alpine
    command:
      - "/bin/sh"
      - "-c"
    args: 
      - "shuf -i 0-100 -n 1 >> /opt/number.out;"
    resources:
      limits:
        memory: "128Mi"
        cpu: "500m"
    ports:
      - containerPort: 8383
    volumes:
    - name: data-volume
      awsElasticBlockStore:
        volumeID: <volume-id>
        fsType: ext4
```

## Persistent Volumes

영구 볼륨은 애플리케이션을 배포하는 사용자가 사용하도록 구성된 클러스터 차원의 볼륨 풀입니다.

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mypv
spec:
  capacity:
    storage: {2:<Size>}
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: slow
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /tmp
    server: 172.17.0.2
```

'accessModes'는 호스트에 볼륨을 마운트하는 방법을 정의합니다. 3가지 모드를 사용할 수 있습니다.

- `ReadOnlyMany`
- `ReadWriteOnce`
- `ReadWriteMany`

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mypv
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  hostPath:
    path: /tmp/data
```

그러나 다중 노드 클러스터가 있고 AWS EBS 등과 같은 일부 스토리지 솔루션이 있는 경우에는 어떻게 될까요? 그러면 localhost 경로를 사용할 수 없습니다.

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mypv
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  awsElasticBlockStore:
    volumeID: <volume-id>
    fsType: ext4
```

```bash
$ kubectl create -f pv.yaml
$ kubectl get pv
```

## Persistent Volume Claims

관리자는 PV를 생성하고 사용자는 PVC를 생성하며, 접근이 승인되면 해당 PVC가 PV에 매핑됩니다.

Kubernetes는 포드의 PVC에 대한 *충분한 용량* 조건을 충족하려고 합니다. 그 외에 다음이 있습니다.

- *Access Modes*
- *Volume Modes*
- *Storage Class*
- *Selector*

그러나 PVC에 대해 일치하는 항목이 여러 개 있는 경우 여전히 라벨과 선택기를 사용하여 PV를 포드에 바인딩할 수 있습니다.

PVC와 PV 간에는 1:1 관계가 있으므로 한 번 제한되면 다른 포드가 PV의 나머지 공간을 사용할 수 없습니다.

또한 PVC에 사용할 수 있는 일치 항목이 없는 경우 클러스터에서 새 볼륨을 사용할 수 있을 때까지 PVC는 계속 '보류 중' 상태입니다. 새 볼륨을 사용할 수 있게 되면 PVC가 자동으로 PV에 바인딩됩니다.

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myclaim
spec:
  resources:
    requests:
      storage: 500Mi
  accessModes:
    - ReadWriteOnce
```

```bash
$ kubectl create -f pvc-definition.yaml
$ kubectl get pvc
```

우리는 처음에 1Gi의 1 PV 'mypv'를 생성했습니다. 500Mi 용량을 가진 다른 PV가 남아 있지 않기 때문에 PVC 'myclaim'은 'mypv'에 매핑됩니다. 그런 다음 PVC는 '바운드' 상태로 이동됩니다.

PVC를 삭제하려면

```bash
$ kubectl delete pvc myclaim
```

그러나 기본적으로 PVC가 삭제되면 PV는 어떻게 됩니까?

기본적으로 PV의 'persistentVolumeReclaimPolicy' 속성은 'Retain'으로 설정됩니다. 즉, PV는 관리자가 수동으로 삭제할 때까지 유지되지만 다른 PVC에 바인딩할 수 없습니다.

PVC의 `persistentVolumeReclaimPolicy` 속성에 대한 여러 옵션이 있습니다.

- `Delete` - PV 삭제는 PVC 삭제에 이어 저장 공간을 확보합니다.
- `Recycle` - PV 데이터 지우기는 PVC 삭제 후 PV를 다른 PVC에 바인딩할 수 있습니다.

## Using PVCs in PODs

O다음과 같이 볼륨 섹션의 `persistentVolumeClaim` 섹션 아래에 PVC 클레임 이름을 지정하여 POD 정의 파일에서 사용하는 PVC를 생성합니다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
      - mountPath: "/var/www/html"
        name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: myclaim
---
apiVersion: v1
kind: Pod
metadata:
  name: webapp
spec:
  containers:
  - name: event-simulator
    image: kodekloud/event-simulator
    env:
    - name: LOG_HANDLERS
      value: file
    volumeMounts:
    - mountPath: /log
      name: log-volume
    resources:
        limits:
          memory: "128Mi"
          cpu: "500m"  
  volumes:
  - name: log-volume
    hostPath:
      # directory location on host
      path: /var/log/webapp
      # this field is optional
      type: Directory
```

ReplicaSet 또는 배포의 경우에도 마찬가지입니다. 레플리카셋에 배포의 포드 템플릿 섹션에 이것을 추가하십시오.

## Storage Class

`pv`를 생성하기 전에 클라우드 또는 일부 스토리지 솔루션에 디스크를 수동으로 프로비저닝해야 합니다.

예를 들어 다음 `pv-definition.yaml`의 경우:

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-vol1
spec:
  capacity:
    storage: 500Mi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  gcePersistentDisk:
    pdName: pd-disk
    fsType: ext4
```

다음과 같은 수동 프로비저닝 명령을 작성해야 합니다.

```bash
$ gcloud beta compute disks create \
		--size 1GB
		--region us-east1
		pd-disk
```

대신 동적 프로비저닝을 위해 'StorageClasses'를 사용할 수 있으며, 이는 시스템에서 스토리지 디스크를 자동으로 프로비저닝할 수 있습니다.

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: google-storage
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-standard
  replication-type: none
```

이제 이것을 PVC에 연결할 수 있습니다.

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myclaim
spec:
  resources:
    requests:
      storage: 500Mi
  accessModes:
    - ReadWriteOnce
  storageClassName: google-storage
```

포드에 연결하는 경우 변경 사항이 없습니다.

```yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
        - mountPath: "/var/www/html"
          name: mypd
      resources:
        limits:
          memory: "128Mi"
          cpu: "500m"
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: myclaim
```
