## Pod Networking

네트워킹 모델의 요구 사항

- 모든 POD에는 IP 주소가 있어야 합니다.
- 모든 POD는 동일한 노드에 있는 다른 모든 POD와 통신할 수 있어야 합니다.
- 모든 POD는 NAT 없이 다른 노드의 동일한 노드에 있는 다른 모든 POD와 통신할 수 있어야 합니다.

예,

노드가 3개 있다고 가정해 보겠습니다.

1. 192.168.1.11
2. 192.168.1.12
3. 192.168.1.13

이 3개의 노드는 192.168.1.0에서 LAN에 연결됩니다.

이제 각 노드에서 브리지 네트워크를 만듭니다.

```shell
ip link add v-net-0 type bridge
# on all 3 nodes and bring them up
ip link set dev v-net-0 up
```

그런 다음 3개 노드 모두에 별도의 서브넷 IP를 할당합니다.

```shell
# on node 1
ip addr add 10.244.1.1/24 dev v-net-0
# on node 2
ip addr add 10.244.2.1/24 dev v-net-0
# on node 3
ip addr add 10.244.3.1/24 dev v-net-0
```

그런 다음 노드 1에서 모든 포드 생성을 게시하기 위해 스크립트 파일인 `net-script.sh`를 작성하고 실행합니다.

```shell
# create veth pair
ip link add .....

# attach veth pair
ip link set .....
ip link set .....

# assign IP Address
ip -n <namespace> addr add .....
ip -n <namespace> route add .....

# bring up interface
ip -n <namespace> link set .....
```

노드 내부의 포드 간에 통신을 설정하는 모든 노드에 대해 동일한 작업이 수행됩니다.

노드 1의 포드와 노드 2의 포드 간의 통신을 설정하려면

```shell
podOnNode1$ ping 10.244.2.2 #ip of pod on node 2
Connect: Network is unreachable

node1$ ip route add 10.244.2.2 via 192.168.1.12
podOnNode1$ ping 10.244.2.2 #ip of pod on node 2
64 bytes from 8.8.8.8: icmp_seq==1 tt=63 time=0.587 ms
```

이제 모든 노드의 컨테이너에 대해 동일한 작업이 수행됩니다. 이 간단한 설정에서는 제대로 작동하지만 대규모 워크로드 클러스터에서는 훨씬 더 많은 구성이 필요합니다.

일반적으로 네트워크에 라우터가 있는 경우 라우터에서 동일한 작업을 수행하는 것이 좋습니다. 그러나 문제는 컨테이너가 생성될 때마다 동일한 명령 집합을 실행해야 한다는 것입니다.

여기에서 CNI가 등장하여 Kubernetes를 돕고 스크립트가 어떻게 보이는지 프로토콜로 안내합니다.

```shell
# net-script.sh

#ADD)
# create veth pair
# attach veth pair
# assign IP Address
# bring up interface

# DEL)
# delete veth pair
```

따라서 컨테이너가 생성될 때마다 `kubelet`은 생성 시 지정된 디렉터리에서 CNI 구성을 찾습니다.

```sh
--cni-conf-dir=/etc/cni/net.d
```

그런 다음 유사하게 지정된 디렉토리에서 스크립트를 찾습니다.

```shell
--cni-bin-dir=/etc/cni/bin
```

그런 다음 컨테이너 이름 및 네임스페이스와 함께 `add` 매개변수로 스크립트를 실행합니다.

```shell
./net-script.sh add <container> <namespace>
```

## CNI in Kubernetes

CNI에 따르면,

- Container Runtime은 네트워크 네임스페이스를 생성해야 합니다.
- 컨테이너가 연결해야 하는 네트워크를 식별합니다.
- 컨테이너가 추가되면 네트워크 플러그인(브리지)을 호출하는 컨테이너 런타임.
- 컨테이너가 삭제될 때 네트워크 플러그인(브리지)을 호출하는 컨테이너 런타임.
- 네트워크 구성의 JSON 형식.

## CNI Weaveworks

Weavework는 P2P 설정을 실행합니다. 여기에서 실행 중인 모든 노드에 'Weavework' 데몬/서비스를 배치합니다. 노드 내부의 통신은 `weavework` 데몬과 `pods` 사이에서 이루어지지만 노드 외부에서는 `weavework` 데몬 사이에서 통신이 이루어집니다.

클러스터에 `weavework` 데몬을 배포하기 위해 다음을 실행합니다.

```shell
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
```

`weavework` 포드를 보려면 다음을 사용합니다. `kubectl get pods -n kube-system | grep weave`.

kubelet 서비스를 검사하고 Kubernetes용으로 구성된 네트워크 플러그인을 식별합니다.

```sh
ps -aux | grep kubelet | grep --color network-plugin=
```

시스템에 적용된 CNI 솔루션을 확인합니다.

```shell
ll /opt/cni/bin
```

이 kubernetes 클러스터에서 사용하도록 구성된 CNI 플러그인은 무엇입니까?

```sh
ls /etc/cni/net.d/
```

> 명심해야 할 사항:
>
> 클러스터에 `weavework`를 배포하라는 메시지가 표시되면 기본적으로 `weavework`에서 사용하는 IP 주소 및 서브넷 범위는 `10.32.0.0/12`이며 호스트 시스템 IP 주소와 겹치는 경우가 많습니다. 예를 들어, 특정 호스트에서 `ip a | grep eth0`은 다음을 생성합니다.
>
> ```sh
> $ ip a | grep eth0
> 12396: eth0@if12397: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default
>     inet 10.40.56.3/24 brd 10.40.56.255 scope global eth0
> ```
>
> 기본 IP 주소를 변경하지 않고 weave 매니페스트 파일을 직접 배포하면 호스트 시스템 IP 주소와 겹치므로 weave 포드가 `오류` 또는 `CrashLoopBackOff` 상태가 됩니다.
>
> 더 깊이 들어가 로그를 검사하면 문제를 명확하게 볼 수 있습니다.
>
> ```sh
> $ kubectl logs -n kube-system weave-net-6mckb -c weave
> Network 10.32.0.0/12 overlaps with existing route 10.40.56.0/24 on host
> ```
>
> 따라서 매니페스트 파일 끝에 `&env.IPALLOC_RANGE=10.50.0.0/16` 옵션을 추가하여 기본 IP 주소를 변경해야 합니다. 다음과 같아야 합니다.
>
> ```sh
> kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')&env.IPALLOC_RANGE=10.50.0.0/16"
> ```

## IP Address Management - Weave

CNI 플러그인 책임:

- ADD/DEL/CHECK 인수를 지원해야 합니다.
- 매개변수 컨테이너 ID, 네트워크 ns 등을 지원해야 합니다.
- **POD에 대한 IP 주소 할당을 관리해야 합니다.**
- 특정 형식으로 결과를 반환해야 합니다.

그러나 IP를 관리하거나 얻는 방법은 무엇입니까?

이를 위해 `DHCP` 또는 `host-local`을 사용합니다. 이는 IPAM 플러그인 구성에서도 변경할 수 있습니다.

```shell
cat /etc/cni/net.d/net-script.conf
{
 ....
 "ipam": {
  "type": "host-local",
  "subnet": "10.244.0.0/16",
  "routes": [
   {
    "dst" : "0.0.0.0/0"
   }
  ]
 }
 ....
}
```

`weaveworks`가 이 IP 관리를 어떻게 하는지 봅시다. 기본적으로 `weavework`에는 IP 범위 `10.32.0.0/12`가 있으며 이는 IP 범위가 `10.32.0.1, 10.32.0.2, ........, 10.47.255.254`(~100만개에 가까운 IP)임을 의미합니다. ).

<https://www.baeldung.com/cs/get-ip-range-from-subnet-mask>

weave로 구성된 POD IP 주소 범위는 무엇입니까?

```shell
ip addr show <network-bridge-name>
```

node01에서 예약된 POD에 구성된 기본 게이트웨이는 무엇입니까?

_node01에서 포드를 예약하고 ip route 출력을 확인하십시오._

```shell
kubectl run busybox --image=busybox --command sleep 1000 --dry-run=client -o yaml > pod.yaml
# open pod.yaml and add nodeName field under spec section.
kubectl create -f pod.yaml
kubectl exec busybox -- sh
ip r # gives you the default gateway
```

## Service Networking

![complete diagram](https://github.com/aditya109/learning-k8s/blob/main/assets/service-networking.svg?raw=true)

클러스터 설정에서 팟(Pod)이 서로 통신하는 방식입니다.

그러나 어떻게 작동합니까?

위와 같이 3노드 클러스터 설정을 살펴보겠습니다.

각 노드에는 IP가 있고 `kube-apiserver`를 통해 클러스터에서 발생하는 변경 사항을 관찰하는 오버워치 역할을 하는 `kubelet`을 실행합니다.

클러스터에서 포드를 생성해야 할 때마다 'kubelet'은 포드를 생성하고 CNI 플러그인을 호출하여 포드에서 네트워킹 구성을 구성합니다.
마찬가지로 각 노드는 `kube-apiserver`를 통해 클러스터의 변경 사항을 감시하는 `kube-proxy`도 실행합니다. 서비스가 생성될 때마다 `kube-apiserver` 설치 중에 `--service-cluster-ip-range` 플래그 아래 지정된 사전 정의된 범위 내에서 할당된 IP를 사용하여 클러스터 전체 가상 객체로 생성됩니다.

범위는 다음을 사용하여 찾을 수도 있습니다.

```sh
ps aux | grep kube-apiserver | grep --service-cluster-ip-range
root       16488 17.3  2.0 1105664 326124 ?      Ssl  20:28   0:10 kube-apiserver --advertise-address=192.168.49.2 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/var/lib/minikube/certs/ca.crt --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota --enable-bootstrap-token-auth=true --etcd-cafile=/var/lib/minikube/certs/etcd/ca.crt --etcd-certfile=/var/lib/minikube/certs/apiserver-etcd-client.crt --etcd-keyfile=/var/lib/minikube/certs/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-client-certificate=/var/lib/minikube/certs/apiserver-kubelet-client.crt --kubelet-client-key=/var/lib/minikube/certs/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/var/lib/minikube/certs/front-proxy-client.crt --proxy-client-key-file=/var/lib/minikube/certs/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=8443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/minikube/certs/sa.pub --service-account-signing-key-file=/var/lib/minikube/certs/sa.key --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/var/lib/minikube/certs/apiserver.crt --tls-private-key-file=/var/lib/minikube/certs/apiserver.key
```

여기서 보시다시피 `10.96.0.0/12`입니다.

'kube-proxy'는 이러한 서비스 관련 IP를 가져오고 각 노드에서 전달 규칙을 생성하여 필요한 포드로 트래픽을 다시 라우팅합니다.

그러나 이러한 규칙은 어떻게 생성됩니까?

`kube-proxy`는 3가지 방법으로 이러한 규칙을 생성합니다.

1. `ipvs`
2. `iptables` (default)
3. `userspace`

> `kube-proxy`를 설치하는 동안 `--proxy-made` 플래그를 설정하여 구성할 수 있습니다.
>
> 프록시 모드 유형을 찾으려면 다음을 사용할 수 있습니다.
>
> ```sh
> kubectl logs <kube-proxy-pod-name> -n kube-system | grep proxy | grep mode
> ```

iptable 항목을 보려면 다음을 사용하십시오.

```shell
iptables -L -t nat | grep <service_name>
```

이 클러스터의 POD에 대해 구성된 IP 주소 범위를 가져오려면

```sh
kubectl logs <weave-pod-name> weave -n kube-system | grep ipalloc-range
```

클러스터가 있는 서비스에 대해 구성된 IP 범위를 가져오려면

```shell
cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep cluster-ip-range
```

## DNS in Kubernetes


IP가 '10.244.2.5'인 Pod 'web'이 있다고 가정해 보겠습니다. IP가 `10.244.1.5`인 `test` 포드를 통해 액세스하려고 합니다.

이를 위해 `10.107.37.188` IP를 할당받는 `web-services` 서비스를 생성합니다. 이 서비스가 생성되는 즉시 Kube DNS에 이 서비스에 대한 항목이 생성됩니다. 이제 모든 팟(Pod)이 이름 또는 전체 이름으로 서비스에 도달할 수 있습니다. 엔트리 테이블은 다음과 같습니다.

| Hostname    | Namespace | Type | Root          | IP Address    |
| ----------- | --------- | ---- | ------------- | ------------- |
| web-service | apps      | svc  | cluster.local | 10.107.37.188 |
| 10-244-2-5  | default   | pod  | cluster.local | 10.244.2.5    |
| 10-244-1-5  | apps      | pod  | cluster.local | 10.244.1.5    |

`test`와 `web`이 동일한 네임스페이스에 있는 경우 `curl http://web-service`를 사용할 수 있습니다.
`test`와 `web`이 다른 네임스페이스(`apps`의 `web` 및 `default`의 `test`)에 있는 경우 `curl http://web-service.apps`를 사용할 수 있습니다.

마지막으로 정규화된 도메인 이름을 사용하여 `curl http://web-service.apps.svc.cluster.local`을 만들 수 있습니다.

> 포드에 대한 레코드는 암시적으로 생성되지 않습니다.
> 그러나 활성화된 경우 **Hostname** 팟에 이름 대신 대시로 대체된 IP가 표시되더라도 팟 레코드가 생성됩니다.

## Core DNS in Kubernetes

Kubernetes 클러스터에서는 `/etc/coredns/Corefile`에서 구성을 가져오는 실행 가능한 `./Coredns`를 실행합니다.

```sh
.:53 {
 errors
 health
 kubernetes cluster.local in-addr.arpa ip6.arpa {
  pods insecure
  upstream
  fallthrough in-addr.arpa ip6.arpa
 }
 prometheus :9153
 proxy . /etc/resolv.conf
 cache 30
 reload
}
```

이는 configMap 객체를 CoreDNS 팟(Pod)으로 전달합니다.

포드 또는 서비스가 생성될 때마다 CoreDNS는 지정된 객체에 대한 항목을 생성합니다.

CoreDNS는 또한 자신에게 테더링된 서비스를 생성합니다.

```sh
kubectl get service -n kube-system
NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   14d
```

포드의 경우 DNS 확인을 위해 `/etc/resolv.conf`에 키-값 쌍이 필요합니다. CoreDNS 서버 `kube-dns` IP는 nameserver의 값으로 배치됩니다.

```sh
cat /etc/resolv.conf
nameserver 10.96.0.10
search default.svc.cluster.local svc.cluster.local cluster.local
```

또한 이 파일에는 포드가 서비스를 해결하는 데 도움이 되는 `search`라는 또 다른 항목이 있습니다.

> 포드의 경우 항상 정규화된 이름을 사용해야 합니다.

이 값은 `/var/lib/kubelet/config.yaml`에도 배치되므로 `kubelet`에서 처리합니다.

```sh
cat /var/lib/kubelet/config.yaml
...
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
```

> `hr` 포드 `nslookup`에서 `mysql` 서비스로 출력을 `/root/CKA/nslookup.out` 파일로 리디렉션합니다.
>
> ```sh
> kubectl exec -it hr -- nslookup mysql.payroll > /root/CKA/nslookup.out
> ```
